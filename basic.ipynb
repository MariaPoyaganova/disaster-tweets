{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjAfQzdlNaQJ",
        "colab_type": "code",
        "outputId": "ed9f27f7-01dc-446c-fe2e-a36f2523f974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD3lyPo3OCrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/gdrive/My Drive/train_tweets.csv', encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "debKsvhlOUMx",
        "colab_type": "code",
        "outputId": "4e569136-8e8a-4b40-f27a-3d782da1f82b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td8M_eU4OV43",
        "colab_type": "code",
        "outputId": "270bbfa4-9b66-4b81-9ec4-7c1758ecd5ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aad3tJUuSi0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(['keyword', 'location'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6EWtsG0Si9w",
        "colab_type": "code",
        "outputId": "c538de7d-b998-43b3-8ad3-c323c9fba13e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               text  target\n",
              "0   1  Our Deeds are the Reason of this #earthquake M...       1\n",
              "1   4             Forest fire near La Ronge Sask. Canada       1\n",
              "2   5  All residents asked to 'shelter in place' are ...       1\n",
              "3   6  13,000 people receive #wildfires evacuation or...       1\n",
              "4   7  Just got sent this photo from Ruby #Alaska as ...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVpqcf7W0DI_",
        "colab_type": "text"
      },
      "source": [
        "Сделаем предобработку с помощью spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_emaTeySjAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en',disable=['parser', 'ner', 'textcat'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2O5aRFESjGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def reduce_to_double_max(text):\n",
        "    text = re.sub(r'(\\w)\\1{2,}', r'\\1\\1', text)\n",
        "    return re.sub(r'(\\W)\\1+', r'\\1', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMA0oJ_VSjJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_corpus(corpus):\n",
        "    corpus = (reduce_to_double_max(s.lower()) for s in corpus)\n",
        "    docs = nlp.pipe(corpus, batch_size=1000, n_threads=4)\n",
        "    return [' '.join([x.lemma_ for x in doc if x.is_alpha]) for doc in docs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qsgsf2bSjMW",
        "colab_type": "code",
        "outputId": "41579a20-6f35-42f8-d293-72c58cbf3b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_processed = preprocess_corpus(df['text'])\n",
        "df['text'] = train_processed\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-PRON- deed be the reason of this earthquake m...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>forest fire near la ronge sask canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>all resident ask to shelter in place be be not...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>people receive wildfire evacuation order in ca...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>just get send this photo from ruby alaska as s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               text  target\n",
              "0   1  -PRON- deed be the reason of this earthquake m...       1\n",
              "1   4              forest fire near la ronge sask canada       1\n",
              "2   5  all resident ask to shelter in place be be not...       1\n",
              "3   6  people receive wildfire evacuation order in ca...       1\n",
              "4   7  just get send this photo from ruby alaska as s...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKSJsRz10JGA",
        "colab_type": "text"
      },
      "source": [
        "Поделим на тестовую и тренировочную выборки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOAD2DMxUqC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(df['text'], df['target'], test_size=0.3, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY_LttQj0OtX",
        "colab_type": "text"
      },
      "source": [
        "Векторизуем твиты с помощью Tf-idf Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShyfzxkHUHUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(max_df=0.87,\n",
        "               smooth_idf=1, max_features=300000)\n",
        "#tf-idf\n",
        "train_vecs =  vectorizer.fit_transform(x_train)\n",
        "test_vecs = vectorizer.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLi3cAV00WjF",
        "colab_type": "text"
      },
      "source": [
        "Перед нейронными сетями посмотрим на резульаьты классификатора - логистическая регрессия "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_xZyAG_UHX3",
        "colab_type": "code",
        "outputId": "493ac95c-dac2-40ab-eee5-15b5746eaf8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression(C=12, max_iter=10000, dual=False)\n",
        "logreg.fit(train_vecs, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=12, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx3TlNhAUHcM",
        "colab_type": "code",
        "outputId": "687b3854-a291-412a-e0f3-2d48778aa1ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_test, logreg.predict(test_vecs)))\n",
        "print(f1_score(y_test, logreg.predict(test_vecs)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7880910683012259\n",
            "0.7452631578947368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbOqYdlH0e2J",
        "colab_type": "text"
      },
      "source": [
        "Как мы видим, результаты не самые хорошие, поэтому переходим к более сложным методам классификации "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZH9xEDzYO33",
        "colab_type": "text"
      },
      "source": [
        "##NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syZvQXcyevUH",
        "colab_type": "code",
        "outputId": "8119fc8e-a93a-4d08-ad8f-e46d73930f69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyFE8na8d5YD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, activation='sigmoid', input_dim=input_shape))\n",
        "    #model.add(Dense(64, activation='sigmoid'))\n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8zIQq2eeX3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = train_vecs.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N41HhY2b0m8v",
        "colab_type": "text"
      },
      "source": [
        "Сначала применим модель Sequential к данным, репрезентированным путём tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vo5Df53d-_Y",
        "colab_type": "code",
        "outputId": "422fcd01-f9ba-479f-c98d-1b01be5a19c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model = build_model(input_shape)\n",
        "model.fit(train_vecs, y_train,\n",
        "          validation_data=(test_vecs, y_test),\n",
        "                    epochs=10, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5329 samples, validate on 2284 samples\n",
            "Epoch 1/10\n",
            "5329/5329 [==============================] - 3s 638us/step - loss: 0.7093 - acc: 0.6157 - val_loss: 0.6265 - val_acc: 0.7793\n",
            "Epoch 2/10\n",
            "5329/5329 [==============================] - 3s 609us/step - loss: 0.5872 - acc: 0.7442 - val_loss: 0.5639 - val_acc: 0.7920\n",
            "Epoch 3/10\n",
            "5329/5329 [==============================] - 3s 606us/step - loss: 0.5129 - acc: 0.8112 - val_loss: 0.5103 - val_acc: 0.7977\n",
            "Epoch 4/10\n",
            "5329/5329 [==============================] - 3s 593us/step - loss: 0.4539 - acc: 0.8321 - val_loss: 0.4817 - val_acc: 0.7938\n",
            "Epoch 5/10\n",
            "5329/5329 [==============================] - 3s 606us/step - loss: 0.4081 - acc: 0.8463 - val_loss: 0.4604 - val_acc: 0.8039\n",
            "Epoch 6/10\n",
            "5329/5329 [==============================] - 3s 595us/step - loss: 0.3744 - acc: 0.8576 - val_loss: 0.4529 - val_acc: 0.8012\n",
            "Epoch 7/10\n",
            "5329/5329 [==============================] - 3s 597us/step - loss: 0.3477 - acc: 0.8658 - val_loss: 0.4564 - val_acc: 0.8074\n",
            "Epoch 8/10\n",
            "5329/5329 [==============================] - 3s 602us/step - loss: 0.3280 - acc: 0.8718 - val_loss: 0.4528 - val_acc: 0.7999\n",
            "Epoch 9/10\n",
            "5329/5329 [==============================] - 3s 609us/step - loss: 0.3098 - acc: 0.8805 - val_loss: 0.4601 - val_acc: 0.7942\n",
            "Epoch 10/10\n",
            "5329/5329 [==============================] - 3s 614us/step - loss: 0.2957 - acc: 0.8876 - val_loss: 0.4662 - val_acc: 0.7929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc632e9eeb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZl_Hku00wjw",
        "colab_type": "text"
      },
      "source": [
        "Качество повысили, теперь оно около 0.8. Теперь попробуем применить ту же модель, но данные представим векторами с помощью модели w2v из модуля spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8W472Lfxuqg",
        "colab_type": "code",
        "outputId": "d32ae690-050b-43d4-e448-741478848901",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "vecs = pd.DataFrame(index = df.index, columns = [d for d in range(96)])\n",
        "vecs.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 96 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    0    1    2    3    4    5    6   ...   89   90   91   92   93   94   95\n",
              "0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
              "1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
              "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
              "3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
              "4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
              "\n",
              "[5 rows x 96 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxncYPYuxuyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "for i, t in enumerate(df['text']): # для каждой строки в датафрейме\n",
        "    t_vec = (nlp(' '.join(t))).vector # векторизуем текст\n",
        "    if t_vec.shape == (0,):\n",
        "        vecs.values[i] = np.array(0)*128 # заменяем строчки на наш вектор\n",
        "    else:\n",
        "        vecs.values[i] = t_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFNE93bDyanb",
        "colab_type": "code",
        "outputId": "6924a870-5c61-47ef-9628-f868f7d7ac30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "vecs.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.99564</td>\n",
              "      <td>-0.978775</td>\n",
              "      <td>0.713813</td>\n",
              "      <td>0.235606</td>\n",
              "      <td>1.35511</td>\n",
              "      <td>0.69002</td>\n",
              "      <td>1.5457</td>\n",
              "      <td>0.202649</td>\n",
              "      <td>2.2968</td>\n",
              "      <td>0.586369</td>\n",
              "      <td>0.488076</td>\n",
              "      <td>0.832369</td>\n",
              "      <td>-0.90528</td>\n",
              "      <td>-1.43158</td>\n",
              "      <td>0.645628</td>\n",
              "      <td>-1.58916</td>\n",
              "      <td>-1.15623</td>\n",
              "      <td>0.466831</td>\n",
              "      <td>-0.911409</td>\n",
              "      <td>-2.47672</td>\n",
              "      <td>2.24286</td>\n",
              "      <td>0.997092</td>\n",
              "      <td>-0.00785534</td>\n",
              "      <td>-1.03589</td>\n",
              "      <td>-1.93833</td>\n",
              "      <td>1.14485</td>\n",
              "      <td>-0.347724</td>\n",
              "      <td>-0.574203</td>\n",
              "      <td>3.21022</td>\n",
              "      <td>-1.04248</td>\n",
              "      <td>2.3887</td>\n",
              "      <td>-0.307255</td>\n",
              "      <td>-0.381557</td>\n",
              "      <td>-1.65607</td>\n",
              "      <td>-0.868504</td>\n",
              "      <td>-0.572451</td>\n",
              "      <td>2.18708</td>\n",
              "      <td>-1.16702</td>\n",
              "      <td>-2.04382</td>\n",
              "      <td>-0.745667</td>\n",
              "      <td>...</td>\n",
              "      <td>2.3166</td>\n",
              "      <td>0.558482</td>\n",
              "      <td>-1.32048</td>\n",
              "      <td>-0.0167134</td>\n",
              "      <td>0.10212</td>\n",
              "      <td>0.8885</td>\n",
              "      <td>0.330678</td>\n",
              "      <td>-0.405777</td>\n",
              "      <td>0.93787</td>\n",
              "      <td>0.106477</td>\n",
              "      <td>1.0593</td>\n",
              "      <td>0.0289169</td>\n",
              "      <td>-1.53197</td>\n",
              "      <td>0.60788</td>\n",
              "      <td>-1.88907</td>\n",
              "      <td>0.427591</td>\n",
              "      <td>-0.323255</td>\n",
              "      <td>2.31011</td>\n",
              "      <td>-1.81129</td>\n",
              "      <td>-0.361919</td>\n",
              "      <td>-1.34435</td>\n",
              "      <td>-0.00673329</td>\n",
              "      <td>-0.340062</td>\n",
              "      <td>-1.78884</td>\n",
              "      <td>0.886302</td>\n",
              "      <td>-2.38339</td>\n",
              "      <td>-1.19216</td>\n",
              "      <td>-0.114072</td>\n",
              "      <td>1.02176</td>\n",
              "      <td>1.01238</td>\n",
              "      <td>-0.217647</td>\n",
              "      <td>1.62149</td>\n",
              "      <td>-0.0227765</td>\n",
              "      <td>-0.806597</td>\n",
              "      <td>-1.54249</td>\n",
              "      <td>-0.456288</td>\n",
              "      <td>-0.212147</td>\n",
              "      <td>-0.562891</td>\n",
              "      <td>0.535796</td>\n",
              "      <td>1.66736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.77575</td>\n",
              "      <td>-1.38535</td>\n",
              "      <td>0.935037</td>\n",
              "      <td>0.535596</td>\n",
              "      <td>1.62528</td>\n",
              "      <td>0.831153</td>\n",
              "      <td>1.25036</td>\n",
              "      <td>0.122188</td>\n",
              "      <td>2.04809</td>\n",
              "      <td>0.263226</td>\n",
              "      <td>0.867552</td>\n",
              "      <td>0.998177</td>\n",
              "      <td>-0.863411</td>\n",
              "      <td>-1.58543</td>\n",
              "      <td>0.429026</td>\n",
              "      <td>-1.84525</td>\n",
              "      <td>-1.40525</td>\n",
              "      <td>0.678945</td>\n",
              "      <td>-1.20128</td>\n",
              "      <td>-2.1458</td>\n",
              "      <td>1.80976</td>\n",
              "      <td>1.10952</td>\n",
              "      <td>-0.111805</td>\n",
              "      <td>-1.11255</td>\n",
              "      <td>-1.98509</td>\n",
              "      <td>1.23007</td>\n",
              "      <td>-0.665375</td>\n",
              "      <td>0.23013</td>\n",
              "      <td>3.15798</td>\n",
              "      <td>-1.41125</td>\n",
              "      <td>2.93151</td>\n",
              "      <td>-0.797871</td>\n",
              "      <td>-0.134435</td>\n",
              "      <td>-1.853</td>\n",
              "      <td>-0.689617</td>\n",
              "      <td>-0.414588</td>\n",
              "      <td>2.14406</td>\n",
              "      <td>-0.982691</td>\n",
              "      <td>-1.94573</td>\n",
              "      <td>-0.375268</td>\n",
              "      <td>...</td>\n",
              "      <td>2.15243</td>\n",
              "      <td>0.522655</td>\n",
              "      <td>-1.26447</td>\n",
              "      <td>-0.31518</td>\n",
              "      <td>-0.00361823</td>\n",
              "      <td>1.13445</td>\n",
              "      <td>0.760572</td>\n",
              "      <td>-0.536777</td>\n",
              "      <td>1.21942</td>\n",
              "      <td>0.326831</td>\n",
              "      <td>0.729753</td>\n",
              "      <td>-0.451411</td>\n",
              "      <td>-1.37693</td>\n",
              "      <td>0.254745</td>\n",
              "      <td>-2.38411</td>\n",
              "      <td>0.750957</td>\n",
              "      <td>-0.342307</td>\n",
              "      <td>2.03838</td>\n",
              "      <td>-2.26994</td>\n",
              "      <td>-0.204573</td>\n",
              "      <td>-1.50302</td>\n",
              "      <td>-0.456392</td>\n",
              "      <td>-0.346987</td>\n",
              "      <td>-2.20158</td>\n",
              "      <td>0.71643</td>\n",
              "      <td>-2.59417</td>\n",
              "      <td>-1.2974</td>\n",
              "      <td>-0.3372</td>\n",
              "      <td>1.10837</td>\n",
              "      <td>1.53513</td>\n",
              "      <td>-0.424577</td>\n",
              "      <td>1.45173</td>\n",
              "      <td>0.338848</td>\n",
              "      <td>-0.793298</td>\n",
              "      <td>-1.97475</td>\n",
              "      <td>0.170678</td>\n",
              "      <td>0.193809</td>\n",
              "      <td>-0.490569</td>\n",
              "      <td>0.157037</td>\n",
              "      <td>2.29135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.1252</td>\n",
              "      <td>-1.0275</td>\n",
              "      <td>0.914514</td>\n",
              "      <td>0.179625</td>\n",
              "      <td>1.57458</td>\n",
              "      <td>0.585166</td>\n",
              "      <td>1.21476</td>\n",
              "      <td>0.294577</td>\n",
              "      <td>2.17648</td>\n",
              "      <td>0.654426</td>\n",
              "      <td>0.409453</td>\n",
              "      <td>0.954248</td>\n",
              "      <td>-0.93579</td>\n",
              "      <td>-1.37462</td>\n",
              "      <td>0.733018</td>\n",
              "      <td>-2.08135</td>\n",
              "      <td>-1.15565</td>\n",
              "      <td>0.866707</td>\n",
              "      <td>-0.8684</td>\n",
              "      <td>-2.50949</td>\n",
              "      <td>2.23843</td>\n",
              "      <td>1.01257</td>\n",
              "      <td>-0.267528</td>\n",
              "      <td>-1.18484</td>\n",
              "      <td>-1.78756</td>\n",
              "      <td>1.14193</td>\n",
              "      <td>-0.499169</td>\n",
              "      <td>-0.339401</td>\n",
              "      <td>3.42302</td>\n",
              "      <td>-0.900547</td>\n",
              "      <td>2.57165</td>\n",
              "      <td>-0.646779</td>\n",
              "      <td>-0.082643</td>\n",
              "      <td>-1.64714</td>\n",
              "      <td>-1.17846</td>\n",
              "      <td>-0.339277</td>\n",
              "      <td>2.06671</td>\n",
              "      <td>-1.25275</td>\n",
              "      <td>-1.94586</td>\n",
              "      <td>-0.60406</td>\n",
              "      <td>...</td>\n",
              "      <td>2.31459</td>\n",
              "      <td>0.65066</td>\n",
              "      <td>-1.39184</td>\n",
              "      <td>0.0802804</td>\n",
              "      <td>0.0675406</td>\n",
              "      <td>1.07979</td>\n",
              "      <td>0.190765</td>\n",
              "      <td>-0.42645</td>\n",
              "      <td>0.790521</td>\n",
              "      <td>0.247712</td>\n",
              "      <td>0.76131</td>\n",
              "      <td>-0.368171</td>\n",
              "      <td>-1.28154</td>\n",
              "      <td>0.586111</td>\n",
              "      <td>-2.28924</td>\n",
              "      <td>0.758565</td>\n",
              "      <td>0.136997</td>\n",
              "      <td>2.40459</td>\n",
              "      <td>-2.12212</td>\n",
              "      <td>-0.545368</td>\n",
              "      <td>-1.7053</td>\n",
              "      <td>0.2491</td>\n",
              "      <td>-0.141967</td>\n",
              "      <td>-2.27683</td>\n",
              "      <td>0.896544</td>\n",
              "      <td>-2.36395</td>\n",
              "      <td>-1.29055</td>\n",
              "      <td>-0.232844</td>\n",
              "      <td>1.41859</td>\n",
              "      <td>1.36877</td>\n",
              "      <td>-0.383987</td>\n",
              "      <td>1.38272</td>\n",
              "      <td>0.0458584</td>\n",
              "      <td>-0.839032</td>\n",
              "      <td>-1.78011</td>\n",
              "      <td>-0.100456</td>\n",
              "      <td>-0.259412</td>\n",
              "      <td>-0.558393</td>\n",
              "      <td>0.084925</td>\n",
              "      <td>1.94959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.13461</td>\n",
              "      <td>-0.998269</td>\n",
              "      <td>0.870933</td>\n",
              "      <td>-0.096226</td>\n",
              "      <td>1.51231</td>\n",
              "      <td>0.52014</td>\n",
              "      <td>1.56677</td>\n",
              "      <td>0.371827</td>\n",
              "      <td>1.97877</td>\n",
              "      <td>0.630475</td>\n",
              "      <td>0.902592</td>\n",
              "      <td>1.0342</td>\n",
              "      <td>-1.22156</td>\n",
              "      <td>-1.09549</td>\n",
              "      <td>1.0742</td>\n",
              "      <td>-1.98272</td>\n",
              "      <td>-1.2661</td>\n",
              "      <td>1.43237</td>\n",
              "      <td>-0.907956</td>\n",
              "      <td>-2.4002</td>\n",
              "      <td>2.25001</td>\n",
              "      <td>0.900847</td>\n",
              "      <td>-0.682805</td>\n",
              "      <td>-1.39565</td>\n",
              "      <td>-2.0085</td>\n",
              "      <td>0.847057</td>\n",
              "      <td>-1.08428</td>\n",
              "      <td>-0.166518</td>\n",
              "      <td>3.55835</td>\n",
              "      <td>-0.626476</td>\n",
              "      <td>2.71963</td>\n",
              "      <td>-0.494648</td>\n",
              "      <td>-0.419137</td>\n",
              "      <td>-1.58559</td>\n",
              "      <td>-0.581029</td>\n",
              "      <td>-0.607018</td>\n",
              "      <td>1.753</td>\n",
              "      <td>-1.08057</td>\n",
              "      <td>-1.74407</td>\n",
              "      <td>-0.680055</td>\n",
              "      <td>...</td>\n",
              "      <td>2.10882</td>\n",
              "      <td>0.522664</td>\n",
              "      <td>-1.08204</td>\n",
              "      <td>0.208593</td>\n",
              "      <td>0.38456</td>\n",
              "      <td>1.10166</td>\n",
              "      <td>0.00540756</td>\n",
              "      <td>-0.414888</td>\n",
              "      <td>0.442331</td>\n",
              "      <td>0.787829</td>\n",
              "      <td>0.271429</td>\n",
              "      <td>-1.26031</td>\n",
              "      <td>-1.13339</td>\n",
              "      <td>0.611944</td>\n",
              "      <td>-2.23911</td>\n",
              "      <td>0.411871</td>\n",
              "      <td>-0.410887</td>\n",
              "      <td>2.64542</td>\n",
              "      <td>-2.08453</td>\n",
              "      <td>-0.716343</td>\n",
              "      <td>-1.58652</td>\n",
              "      <td>0.311111</td>\n",
              "      <td>-0.0296704</td>\n",
              "      <td>-2.68417</td>\n",
              "      <td>0.458213</td>\n",
              "      <td>-2.1725</td>\n",
              "      <td>-1.46998</td>\n",
              "      <td>-0.359542</td>\n",
              "      <td>1.35469</td>\n",
              "      <td>1.67333</td>\n",
              "      <td>0.306473</td>\n",
              "      <td>0.971012</td>\n",
              "      <td>0.0816446</td>\n",
              "      <td>-0.834373</td>\n",
              "      <td>-1.75675</td>\n",
              "      <td>-0.439515</td>\n",
              "      <td>-0.44193</td>\n",
              "      <td>-0.245959</td>\n",
              "      <td>0.313535</td>\n",
              "      <td>1.93752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.97374</td>\n",
              "      <td>-0.904708</td>\n",
              "      <td>0.616136</td>\n",
              "      <td>0.347864</td>\n",
              "      <td>1.30481</td>\n",
              "      <td>0.831162</td>\n",
              "      <td>1.29754</td>\n",
              "      <td>0.156093</td>\n",
              "      <td>2.27763</td>\n",
              "      <td>0.597022</td>\n",
              "      <td>0.758626</td>\n",
              "      <td>0.685767</td>\n",
              "      <td>-0.862067</td>\n",
              "      <td>-0.939773</td>\n",
              "      <td>0.855174</td>\n",
              "      <td>-1.90946</td>\n",
              "      <td>-1.05183</td>\n",
              "      <td>0.946671</td>\n",
              "      <td>-1.16525</td>\n",
              "      <td>-2.43184</td>\n",
              "      <td>2.18085</td>\n",
              "      <td>0.72194</td>\n",
              "      <td>-0.119579</td>\n",
              "      <td>-1.01934</td>\n",
              "      <td>-1.89843</td>\n",
              "      <td>1.22694</td>\n",
              "      <td>-0.57683</td>\n",
              "      <td>0.0474901</td>\n",
              "      <td>3.45255</td>\n",
              "      <td>-1.14866</td>\n",
              "      <td>2.59992</td>\n",
              "      <td>-0.570179</td>\n",
              "      <td>-0.245786</td>\n",
              "      <td>-1.58028</td>\n",
              "      <td>-1.23558</td>\n",
              "      <td>-0.346025</td>\n",
              "      <td>2.07883</td>\n",
              "      <td>-1.0698</td>\n",
              "      <td>-1.99623</td>\n",
              "      <td>-0.595953</td>\n",
              "      <td>...</td>\n",
              "      <td>2.22834</td>\n",
              "      <td>0.524332</td>\n",
              "      <td>-1.2154</td>\n",
              "      <td>-0.25409</td>\n",
              "      <td>0.0725744</td>\n",
              "      <td>0.921236</td>\n",
              "      <td>0.345316</td>\n",
              "      <td>-0.235305</td>\n",
              "      <td>0.773363</td>\n",
              "      <td>0.300911</td>\n",
              "      <td>0.587272</td>\n",
              "      <td>-0.592632</td>\n",
              "      <td>-1.54162</td>\n",
              "      <td>0.464435</td>\n",
              "      <td>-2.35285</td>\n",
              "      <td>0.81057</td>\n",
              "      <td>-0.563864</td>\n",
              "      <td>1.861</td>\n",
              "      <td>-2.07841</td>\n",
              "      <td>-0.289784</td>\n",
              "      <td>-1.67409</td>\n",
              "      <td>-0.128999</td>\n",
              "      <td>-0.339822</td>\n",
              "      <td>-1.81982</td>\n",
              "      <td>0.807932</td>\n",
              "      <td>-2.39652</td>\n",
              "      <td>-1.17855</td>\n",
              "      <td>0.0619801</td>\n",
              "      <td>1.46991</td>\n",
              "      <td>1.38961</td>\n",
              "      <td>-0.0014042</td>\n",
              "      <td>1.40236</td>\n",
              "      <td>0.0483386</td>\n",
              "      <td>-0.850057</td>\n",
              "      <td>-1.89418</td>\n",
              "      <td>-0.158109</td>\n",
              "      <td>-0.0892788</td>\n",
              "      <td>-0.273811</td>\n",
              "      <td>0.0465797</td>\n",
              "      <td>2.13367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 96 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2   ...        93         94       95\n",
              "0  1.99564 -0.978775  0.713813  ... -0.562891   0.535796  1.66736\n",
              "1  1.77575  -1.38535  0.935037  ... -0.490569   0.157037  2.29135\n",
              "2   2.1252   -1.0275  0.914514  ... -0.558393   0.084925  1.94959\n",
              "3  2.13461 -0.998269  0.870933  ... -0.245959   0.313535  1.93752\n",
              "4  1.97374 -0.904708  0.616136  ... -0.273811  0.0465797  2.13367\n",
              "\n",
              "[5 rows x 96 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHCOTFo71CZF",
        "colab_type": "text"
      },
      "source": [
        "Так же разобьём на тренировочную и тестовую выборки "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ixXGxSCxu3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_wv, x_test_wv, y_train_wv, y_test_wv = train_test_split(vecs, df['target'], test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XklKIdWaBZTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape_1 = x_train_wv.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTUchRBzBN4P",
        "colab_type": "code",
        "outputId": "a015eb28-2db2-4dc8-c16e-b4573ffff4bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model_1 = build_model(input_shape_1)\n",
        "model_1.fit(x_train_wv, y_train_wv,\n",
        "          validation_data=(x_test_wv, y_test_wv),\n",
        "                    epochs=10, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5100 samples, validate on 2513 samples\n",
            "Epoch 1/10\n",
            "5100/5100 [==============================] - 1s 215us/step - loss: 0.6725 - acc: 0.6057 - val_loss: 0.6260 - val_acc: 0.6403\n",
            "Epoch 2/10\n",
            "5100/5100 [==============================] - 0s 62us/step - loss: 0.6354 - acc: 0.6422 - val_loss: 0.6224 - val_acc: 0.6502\n",
            "Epoch 3/10\n",
            "5100/5100 [==============================] - 0s 63us/step - loss: 0.6262 - acc: 0.6514 - val_loss: 0.6538 - val_acc: 0.6057\n",
            "Epoch 4/10\n",
            "5100/5100 [==============================] - 0s 64us/step - loss: 0.6225 - acc: 0.6541 - val_loss: 0.7030 - val_acc: 0.5826\n",
            "Epoch 5/10\n",
            "5100/5100 [==============================] - 0s 65us/step - loss: 0.6209 - acc: 0.6498 - val_loss: 0.6800 - val_acc: 0.5842\n",
            "Epoch 6/10\n",
            "5100/5100 [==============================] - 0s 69us/step - loss: 0.6169 - acc: 0.6627 - val_loss: 0.6221 - val_acc: 0.6550\n",
            "Epoch 7/10\n",
            "5100/5100 [==============================] - 0s 64us/step - loss: 0.6183 - acc: 0.6614 - val_loss: 0.6284 - val_acc: 0.6502\n",
            "Epoch 8/10\n",
            "5100/5100 [==============================] - 0s 69us/step - loss: 0.6156 - acc: 0.6618 - val_loss: 0.6505 - val_acc: 0.6208\n",
            "Epoch 9/10\n",
            "5100/5100 [==============================] - 0s 64us/step - loss: 0.6131 - acc: 0.6682 - val_loss: 0.6062 - val_acc: 0.6769\n",
            "Epoch 10/10\n",
            "5100/5100 [==============================] - 0s 66us/step - loss: 0.6114 - acc: 0.6710 - val_loss: 0.7237 - val_acc: 0.5647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc625725278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbaBEw6R1I6G",
        "colab_type": "text"
      },
      "source": [
        "Качество стало намного хуже, переходим к сеткам посложнее и другой предобученной модели векторов "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta__vbBBdep3",
        "colab_type": "text"
      },
      "source": [
        "#### для эмбеддингов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ste7RjOdJWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 120\n",
        "embedding_dim = 100\n",
        "BatchSize = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzDgOmzp1U73",
        "colab_type": "text"
      },
      "source": [
        "Данных много - понадобиться генератор"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTj2R1rYTlY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import Sequence\n",
        "from keras import layers\n",
        "from keras import Model\n",
        "class DataGenerator(Sequence):\n",
        "    #Generates data for Keras\n",
        "    def __init__(self, texts, labels, batch_size, embedding_dim, max_length, shuffle=False):\n",
        "        self.labels = labels\n",
        "        self.texts = texts\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.batch_size = batch_size\n",
        "        self.max_length = max_length\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "    \n",
        "    def __len__(self):\n",
        "\t\t#'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.texts) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        #'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        temp_texts = [self.texts.iloc[k] for k in indexes]\n",
        "        temp_labels = [self.labels.iloc[k] for k in indexes]\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(temp_texts, temp_labels)        \n",
        "        return X, y\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        #'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.texts))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, temp_texts, temp_labels):\n",
        "        #'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        # Создается тензор с объектами\n",
        "        # Размерность: BATCH_SIZE x MAX_LENGTH x EMBEDDING_DIM\n",
        "        X = np.zeros(shape=(self.batch_size, \n",
        "                            self.max_length, \n",
        "                            self.embedding_dim)) \n",
        "        y = np.zeros((self.batch_size), dtype=int) # Если класс кодируется числом, если в категориальной форма - то размер будет BATCH_SIZE x COUNT_OF_CLASSES\n",
        "        # Generate data\n",
        "        for instance_number in range(self.batch_size):\n",
        "            try:\n",
        "                for current_token in range(self.max_length):\n",
        "                    if temp_texts[instance_number][current_token] in model.vocab:\n",
        "                        X[instance_number,current_token,:] = model.get_vector(temp_texts[instance_number][current_token])# Эмбеддинг этого слова\n",
        "            except IndexError:\n",
        "                pass\n",
        "\n",
        "            y[instance_number] = temp_labels[instance_number]\n",
        "        return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgJljvXMC8d6",
        "colab_type": "code",
        "outputId": "4222b9d0-01fb-49e3-edc5-710af838cbbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import gensim.downloader as api\n",
        "model = api.load(\"glove-wiki-gigaword-100\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpZxzHn01ac5",
        "colab_type": "text"
      },
      "source": [
        "Возьмём сверточную нейросеть с разным числом фильтров (2-5), также используем другую репрезентацию из модели glove-wiki-gigaword-100, вектора с размерностью 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5iYu0f5FIp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CNNModel(\n",
        "    maxlen, # Максимальная длина последовательности\n",
        "    embedding_dim, # разбер эмбеддинга\n",
        "):\n",
        "\n",
        "  COUNT_OF_FILTERS = 256 # Возможно, придется подобрать...\n",
        "  COUNT_OF_NEURONS = 128 # Возможно, придется подобрать...\n",
        "\n",
        "  inputs = layers.Input(shape=(maxlen, embedding_dim))\n",
        "  convs = []\n",
        "  for kernel_size in [2,3,4,5]:\n",
        "    c = layers.Conv1D(COUNT_OF_FILTERS, kernel_size=kernel_size, activation='relu')(inputs)\n",
        "    c = layers.GlobalMaxPool1D()(c)\n",
        "    convs.append(c)\n",
        "  x = layers.Concatenate()(convs)\n",
        "  x = layers.Dropout(0.2)(x)\n",
        "  x = layers.Dense(COUNT_OF_NEURONS, activation = 'tanh')(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "  output = layers.Dense(5, \n",
        "                 activation = 'softmax' # или sigmoid? выберете сами\n",
        "                 )(x)\n",
        "  model = Model(inputs = inputs, outputs = output)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Oev7o7HYzRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "training_generator = DataGenerator(texts=x_train, labels=y_train, batch_size=2, embedding_dim=100, max_length=120)\n",
        "validation_generator = DataGenerator(texts=x_test, labels=y_test, batch_size=2, embedding_dim=100, max_length=120)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZdMUDGrDg1Y",
        "colab_type": "code",
        "outputId": "48c93f73-bbf1-4658-9b49-ff1015e9ee40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "cnnm = CNNModel(120, 100)\n",
        "cnnm.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "cnnm.fit_generator(generator=training_generator,\n",
        "                    validation_data=validation_generator, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2664/2664 [==============================] - 54s 20ms/step - loss: 0.7943 - acc: 0.5178 - val_loss: 0.6940 - val_acc: 0.5709\n",
            "Epoch 2/10\n",
            "2664/2664 [==============================] - 53s 20ms/step - loss: 0.7161 - acc: 0.5362 - val_loss: 0.6834 - val_acc: 0.5709\n",
            "Epoch 3/10\n",
            "2664/2664 [==============================] - 52s 19ms/step - loss: 0.7124 - acc: 0.5437 - val_loss: 0.6848 - val_acc: 0.5705\n",
            "Epoch 4/10\n",
            "2664/2664 [==============================] - 52s 20ms/step - loss: 0.7074 - acc: 0.5364 - val_loss: 0.7494 - val_acc: 0.4291\n",
            "Epoch 5/10\n",
            "2664/2664 [==============================] - 52s 20ms/step - loss: 0.7079 - acc: 0.5355 - val_loss: 0.6836 - val_acc: 0.5705\n",
            "Epoch 6/10\n",
            "2664/2664 [==============================] - 53s 20ms/step - loss: 0.7122 - acc: 0.5297 - val_loss: 0.6840 - val_acc: 0.5709\n",
            "Epoch 7/10\n",
            "2664/2664 [==============================] - 53s 20ms/step - loss: 0.7110 - acc: 0.5327 - val_loss: 0.7209 - val_acc: 0.4291\n",
            "Epoch 8/10\n",
            "2664/2664 [==============================] - 53s 20ms/step - loss: 0.7119 - acc: 0.5268 - val_loss: 0.6861 - val_acc: 0.5705\n",
            "Epoch 9/10\n",
            "2664/2664 [==============================] - 52s 20ms/step - loss: 0.7080 - acc: 0.5343 - val_loss: 0.6847 - val_acc: 0.5705\n",
            "Epoch 10/10\n",
            "2664/2664 [==============================] - 53s 20ms/step - loss: 0.7137 - acc: 0.5291 - val_loss: 0.6972 - val_acc: 0.4291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b5e01f278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7mOxSin29pk",
        "colab_type": "text"
      },
      "source": [
        "Качество, к сожалению, уменьшилось, макисмально здесь получилось - 0.5709"
      ]
    }
  ]
}